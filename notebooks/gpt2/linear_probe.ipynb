{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54b4a6ba",
   "metadata": {
    "papermill": {
     "duration": 0.005449,
     "end_time": "2024-03-23T20:47:06.033910",
     "exception": false,
     "start_time": "2024-03-23T20:47:06.028461",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training a simple linear probe on a transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b3e12a",
   "metadata": {
    "papermill": {
     "duration": 0.003441,
     "end_time": "2024-03-23T20:47:06.041407",
     "exception": false,
     "start_time": "2024-03-23T20:47:06.037966",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this introductory notebook, we will train a simple linear probe for a transformer model to check if causal language modelling understanding for the wikitext dataset is present in a transformer model even at some intermediate layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80043d10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:06.049329Z",
     "iopub.status.busy": "2024-03-23T20:47:06.049083Z",
     "iopub.status.idle": "2024-03-23T20:47:42.632268Z",
     "shell.execute_reply": "2024-03-23T20:47:42.631606Z"
    },
    "papermill": {
     "duration": 36.589463,
     "end_time": "2024-03-23T20:47:42.634311",
     "exception": false,
     "start_time": "2024-03-23T20:47:06.044848",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    MistralForCausalLM,\n",
    "    Trainer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    GPT2Model,\n",
    "    GPT2LMHeadModel,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig\n",
    "import torch\n",
    "\n",
    "# Imports from the transformer_heads library\n",
    "from transformer_heads import load_headed\n",
    "from transformer_heads.util.helpers import DataCollatorWithPadding, get_model_params\n",
    "from transformer_heads.config import HeadConfig\n",
    "from transformer_heads.util.model import print_trainable_parameters\n",
    "from transformer_heads.util.evaluate import evaluate_head_wise, get_top_n_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42e762b",
   "metadata": {
    "papermill": {
     "duration": 0.003609,
     "end_time": "2024-03-23T20:47:42.643557",
     "exception": false,
     "start_time": "2024-03-23T20:47:42.639948",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Set the model and it's model parameters. Default is GPT2, but you can also use Mistral 7b if you have enough GPU RAM (and are willing to wait longer for training to complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7aaf7d13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:42.651847Z",
     "iopub.status.busy": "2024-03-23T20:47:42.651401Z",
     "iopub.status.idle": "2024-03-23T20:47:42.654781Z",
     "shell.execute_reply": "2024-03-23T20:47:42.654313Z"
    },
    "papermill": {
     "duration": 0.008796,
     "end_time": "2024-03-23T20:47:42.655833",
     "exception": false,
     "start_time": "2024-03-23T20:47:42.647037",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# GPT2 is the fastest and requires fewest memory. However, this works just the same with any Llama or Mistral model. Just change model_path to its huggingface path.\n",
    "model_path = \"gpt2\"\n",
    "train_epochs = 1\n",
    "eval_epochs = 1\n",
    "logging_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b281c1da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:42.663798Z",
     "iopub.status.busy": "2024-03-23T20:47:42.663618Z",
     "iopub.status.idle": "2024-03-23T20:47:42.672559Z",
     "shell.execute_reply": "2024-03-23T20:47:42.672095Z"
    },
    "papermill": {
     "duration": 0.014085,
     "end_time": "2024-03-23T20:47:42.673626",
     "exception": false,
     "start_time": "2024-03-23T20:47:42.659541",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model_path = \"gpt2\"\n",
    "train_epochs = 1\n",
    "eval_epochs = 1\n",
    "logging_steps = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5f4b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:42.681451Z",
     "iopub.status.busy": "2024-03-23T20:47:42.681268Z",
     "iopub.status.idle": "2024-03-23T20:47:43.195160Z",
     "shell.execute_reply": "2024-03-23T20:47:43.194683Z"
    },
    "papermill": {
     "duration": 0.519624,
     "end_time": "2024-03-23T20:47:43.196768",
     "exception": false,
     "start_time": "2024-03-23T20:47:42.677144",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'vocab_size': 50257, 'n_positions': 1024, 'n_embd': 768, 'n_layer': 12, 'n_head': 12, 'n_inner': None, 'activation_function': 'gelu_new', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'summary_type': 'cls_index', 'summary_use_proj': True, 'summary_activation': None, 'summary_first_dropout': 0.1, 'summary_proj_to_labels': True, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 50256, 'eos_token_id': 50256, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'chunk_size_feed_forward': 0, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': ['GPT2LMHeadModel'], 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': {'text-generation': {'do_sample': True, 'max_length': 50}}, 'problem_type': None, '_name_or_path': 'gpt2', 'transformers_version': '4.37.2', 'model_type': 'gpt2', 'n_ctx': 1024, 'model_class': <class 'transformers.models.gpt2.modeling_gpt2.GPT2LMHeadModel'>, 'hidden_size': 768}\n"
     ]
    }
   ],
   "source": [
    "model_params = get_model_params(model_path)\n",
    "model_class = model_params[\"model_class\"]\n",
    "hidden_size = model_params[\"hidden_size\"]\n",
    "vocab_size = model_params[\"vocab_size\"]\n",
    "print(model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e414c4c",
   "metadata": {
    "papermill": {
     "duration": 0.003605,
     "end_time": "2024-03-23T20:47:43.204351",
     "exception": false,
     "start_time": "2024-03-23T20:47:43.200746",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Start out by configuring the linear probing head. In this example we hook at layer -4. This is using the python indexing format. E.g. gpt-2 has 12 transformer blocks. Hooking at layer -4 means that the linear probe processes the hidden state after the 9th layer while hooking at layer -1 would mean processing the hidden state after the last (12th) transformer block.\n",
    "\n",
    "Otherwise, we are setting *num_layers* to 1, to make sure that we are actually training a *linear* probe and not an mlp. With *is_causal_lm* we specify the type of task that the model is supposed to learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6444d2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:43.213445Z",
     "iopub.status.busy": "2024-03-23T20:47:43.213253Z",
     "iopub.status.idle": "2024-03-23T20:47:43.216598Z",
     "shell.execute_reply": "2024-03-23T20:47:43.216117Z"
    },
    "papermill": {
     "duration": 0.008649,
     "end_time": "2024-03-23T20:47:43.217627",
     "exception": false,
     "start_time": "2024-03-23T20:47:43.208978",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "heads_configs = [\n",
    "    HeadConfig(\n",
    "        name=\"wikitext_head\",\n",
    "        layer_hook=-4,  # Hook to layer [-4] (Drop 3 layers from the end)\n",
    "        in_size=hidden_size,\n",
    "        num_layers=1,\n",
    "        output_activation=\"linear\",\n",
    "        is_causal_lm=True,\n",
    "        loss_fct=\"cross_entropy\",\n",
    "        num_outputs=vocab_size,\n",
    "        is_regression=False,\n",
    "        output_bias=False,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264f547a",
   "metadata": {
    "papermill": {
     "duration": 0.003675,
     "end_time": "2024-03-23T20:47:43.224940",
     "exception": false,
     "start_time": "2024-03-23T20:47:43.221265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now we load and format our dataset. We need to make sure that the dataset has labels stored for each head that we want to train. In case of the causal language modelling task, these labels are just copys of the input_ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5faaf4d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:43.233162Z",
     "iopub.status.busy": "2024-03-23T20:47:43.232763Z",
     "iopub.status.idle": "2024-03-23T20:47:53.573073Z",
     "shell.execute_reply": "2024-03-23T20:47:53.572502Z"
    },
    "papermill": {
     "duration": 10.346162,
     "end_time": "2024-03-23T20:47:53.574742",
     "exception": false,
     "start_time": "2024-03-23T20:47:43.228580",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd = load_dataset(\"wikitext\", \"wikitext-2-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e07be6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:53.583697Z",
     "iopub.status.busy": "2024-03-23T20:47:53.583429Z",
     "iopub.status.idle": "2024-03-23T20:47:56.453080Z",
     "shell.execute_reply": "2024-03-23T20:47:56.452561Z"
    },
    "papermill": {
     "duration": 2.875777,
     "end_time": "2024-03-23T20:47:56.454668",
     "exception": false,
     "start_time": "2024-03-23T20:47:53.578891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1870d6c6b1947cbbf6c1767d7d41ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23627 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    out = tokenizer(examples[\"text\"], padding=False, truncation=True)\n",
    "    out[heads_configs[0].name] = out[\"input_ids\"].copy()\n",
    "    return out\n",
    "\n",
    "\n",
    "for split in dd.keys():\n",
    "    dd[split] = dd[split].filter(function=lambda example: len(example[\"text\"]) > 10)\n",
    "    dd[split] = dd[split].map(tokenize_function, batched=True)\n",
    "dd.set_format(\n",
    "    type=\"torch\", columns=[\"input_ids\", \"attention_mask\", heads_configs[0].name]\n",
    ")\n",
    "for split in dd.keys():\n",
    "    dd[split] = dd[split].remove_columns(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78131ee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:56.463973Z",
     "iopub.status.busy": "2024-03-23T20:47:56.463769Z",
     "iopub.status.idle": "2024-03-23T20:47:56.467731Z",
     "shell.execute_reply": "2024-03-23T20:47:56.467265Z"
    },
    "papermill": {
     "duration": 0.009843,
     "end_time": "2024-03-23T20:47:56.468878",
     "exception": false,
     "start_time": "2024-03-23T20:47:56.459035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'wikitext_head'],\n",
       "    num_rows: 23627\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd[\"train\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f75133e",
   "metadata": {
    "papermill": {
     "duration": 0.003909,
     "end_time": "2024-03-23T20:47:56.476928",
     "exception": false,
     "start_time": "2024-03-23T20:47:56.473019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Now it is time to load our model. The load_headed function of transformer_heads is great for loading frozen models with a linear probe. To save GPU memory, we will load the model in a quantized state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "416838c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:47:56.485616Z",
     "iopub.status.busy": "2024-03-23T20:47:56.485432Z",
     "iopub.status.idle": "2024-03-23T20:48:05.710241Z",
     "shell.execute_reply": "2024-03-23T20:48:05.709607Z"
    },
    "papermill": {
     "duration": 9.230758,
     "end_time": "2024-03-23T20:48:05.711621",
     "exception": false,
     "start_time": "2024-03-23T20:47:56.480863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of TransformerWithHeads were not initialized from the model checkpoint at gpt2 and are newly initialized: ['heads.wikitext_head.lins.0.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    load_in_8bit=False,\n",
    "    llm_int8_threshold=6.0,\n",
    "    llm_int8_has_fp16_weight=False,\n",
    "    bnb_4bit_compute_dtype=torch.float32,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    ")\n",
    "\n",
    "model = load_headed(\n",
    "    model_class,\n",
    "    model_path,\n",
    "    head_configs=heads_configs,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map={\"\": torch.cuda.current_device()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba0b48",
   "metadata": {
    "papermill": {
     "duration": 0.004219,
     "end_time": "2024-03-23T20:48:05.720535",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.716316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "That warning about weights not initialized from the model checkpoint is exactly what we want to see. We want a newly initialized linear probe that is not in the pretrained gpt2 checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30323ad5",
   "metadata": {
    "papermill": {
     "duration": 0.004282,
     "end_time": "2024-03-23T20:48:05.728887",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.724605",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's check some data about our model using the convenience method *print_trainable_parameters*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe7ca798",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:48:05.738352Z",
     "iopub.status.busy": "2024-03-23T20:48:05.737995Z",
     "iopub.status.idle": "2024-03-23T20:48:05.742241Z",
     "shell.execute_reply": "2024-03-23T20:48:05.741654Z"
    },
    "papermill": {
     "duration": 0.010246,
     "end_time": "2024-03-23T20:48:05.743401",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.733155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all params: 120569856 || trainable params: 38597376 || trainable%: 32.01245923359152\n",
      "params by dtype: defaultdict(<class 'int'>, {torch.float32: 78102528, torch.uint8: 42467328})\n",
      "trainable params by dtype: defaultdict(<class 'int'>, {torch.float32: 38597376})\n"
     ]
    }
   ],
   "source": [
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83bae86",
   "metadata": {
    "papermill": {
     "duration": 0.004089,
     "end_time": "2024-03-23T20:48:05.751733",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.747644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Given that gpt2 is a fairly small model with a large vocab size, our single linear probe already has quite a lot of parameters compared to the rest of the model. Every parameter in the model that is not part of the linear probe is frozen (has requires_grad set to false)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d63b570",
   "metadata": {
    "papermill": {
     "duration": 0.004147,
     "end_time": "2024-03-23T20:48:05.760142",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.755995",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Let's see how our linear probe performs before it is trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6032324a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:48:05.769183Z",
     "iopub.status.busy": "2024-03-23T20:48:05.768986Z",
     "iopub.status.idle": "2024-03-23T20:48:07.742818Z",
     "shell.execute_reply": "2024-03-23T20:48:07.742135Z"
    },
    "papermill": {
     "duration": 1.979807,
     "end_time": "2024-03-23T20:48:07.744051",
     "exception": false,
     "start_time": "2024-03-23T20:48:05.764244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wikitext_head': ['aunder', ' mesh', 'inki', 'Thread', ' Prediction']}\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    get_top_n_preds(\n",
    "        n=5, model=model, text=\"The historical significance of\", tokenizer=tokenizer\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e528e3",
   "metadata": {
    "papermill": {
     "duration": 0.004313,
     "end_time": "2024-03-23T20:48:07.753141",
     "exception": false,
     "start_time": "2024-03-23T20:48:07.748828",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "As expected, this is pretty random.\n",
    "\n",
    "Let's train the linear probe now using huggingfaces simple to use Trainer class. Note that we are using a custom collator here, to handle the labels under the heads_configs names correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fce0ef54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:48:07.762938Z",
     "iopub.status.busy": "2024-03-23T20:48:07.762561Z",
     "iopub.status.idle": "2024-03-23T20:55:07.276825Z",
     "shell.execute_reply": "2024-03-23T20:55:07.276197Z"
    },
    "papermill": {
     "duration": 419.520737,
     "end_time": "2024-03-23T20:55:07.278207",
     "exception": false,
     "start_time": "2024-03-23T20:48:07.757470",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mykeller\u001b[0m (\u001b[33mchm-hci\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.16.4 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.16.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/raven/u/ykeller/transformer_heads/wandb/run-20240323_214812-zpv7qa6m\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mmajor-sunset-208\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/chm-hci/huggingface\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/chm-hci/huggingface/runs/zpv7qa6m\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2954' max='2954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2954/2954 06:40, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>10.900800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>7.522400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.429900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>5.740400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>5.528000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>5.313400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>5.220800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>5.102600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>5.031800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>5.025600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.886800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.827500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.839700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>4.762400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>4.690500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>4.663900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>4.635100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>4.664100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>4.580400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>4.481000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>4.525600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>4.505800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>4.496100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>4.519800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>4.482800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>4.484200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>4.465100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>4.469000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory linear_probe_test/checkpoint-500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory linear_probe_test/checkpoint-1000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory linear_probe_test/checkpoint-1500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory linear_probe_test/checkpoint-2000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory linear_probe_test/checkpoint-2500 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2954, training_loss=5.186163890014731, metrics={'train_runtime': 415.5038, 'train_samples_per_second': 56.864, 'train_steps_per_second': 7.109, 'total_flos': 4454006226937344.0, 'train_loss': 5.186163890014731, 'epoch': 1.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\"linear_probe_test\",\n",
    "    learning_rate=0.0002,\n",
    "    num_train_epochs=train_epochs,\n",
    "    logging_steps=logging_steps,\n",
    "    do_eval=False,\n",
    "    remove_unused_columns=False,  # Important to set to False, otherwise things will fail\n",
    ")\n",
    "collator = DataCollatorWithPadding(\n",
    "    feature_name_to_padding_value={\n",
    "        \"input_ids\": tokenizer.pad_token_id,\n",
    "        heads_configs[0].name: -100,\n",
    "        \"attention_mask\": 0,\n",
    "    }\n",
    ")\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args=args,\n",
    "    train_dataset=dd[\"train\"],\n",
    "    data_collator=collator,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b7f4d",
   "metadata": {
    "papermill": {
     "duration": 0.005657,
     "end_time": "2024-03-23T20:55:07.290960",
     "exception": false,
     "start_time": "2024-03-23T20:55:07.285303",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "So this is nice to see, the probe is learning something and the training loss decreases. But how about evaluation on the validation set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79a8227e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:55:07.303299Z",
     "iopub.status.busy": "2024-03-23T20:55:07.303077Z",
     "iopub.status.idle": "2024-03-23T20:55:53.067372Z",
     "shell.execute_reply": "2024-03-23T20:55:53.066686Z"
    },
    "papermill": {
     "duration": 45.772106,
     "end_time": "2024-03-23T20:55:53.068574",
     "exception": false,
     "start_time": "2024-03-23T20:55:07.296468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   0%|          | 0/308 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u/ykeller/conda-envs/sh_finetuning/lib/python3.10/site-packages/torch/utils/checkpoint.py:90: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "\r\n",
      "Evaluating:   0%|          | 1/308 [00:00<00:42,  7.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   1%|          | 2/308 [00:00<00:36,  8.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   1%|‚ñè         | 4/308 [00:00<00:31,  9.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   2%|‚ñè         | 5/308 [00:00<00:36,  8.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   2%|‚ñè         | 6/308 [00:00<00:45,  6.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   2%|‚ñè         | 7/308 [00:01<00:49,  6.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   3%|‚ñé         | 8/308 [00:01<00:49,  6.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   3%|‚ñé         | 9/308 [00:01<00:50,  5.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   3%|‚ñé         | 10/308 [00:01<00:57,  5.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   4%|‚ñé         | 11/308 [00:01<00:52,  5.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   4%|‚ñç         | 12/308 [00:01<00:47,  6.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   4%|‚ñç         | 13/308 [00:01<00:42,  6.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   5%|‚ñç         | 15/308 [00:02<00:35,  8.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   5%|‚ñå         | 16/308 [00:02<00:37,  7.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   6%|‚ñå         | 17/308 [00:02<00:37,  7.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   6%|‚ñå         | 18/308 [00:02<00:38,  7.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   6%|‚ñå         | 19/308 [00:02<00:46,  6.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   6%|‚ñã         | 20/308 [00:03<00:49,  5.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   7%|‚ñã         | 21/308 [00:03<00:44,  6.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   8%|‚ñä         | 24/308 [00:03<00:34,  8.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   8%|‚ñä         | 25/308 [00:03<00:35,  7.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   9%|‚ñâ         | 27/308 [00:03<00:28,  9.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:   9%|‚ñâ         | 29/308 [00:03<00:25, 11.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  10%|‚ñà         | 31/308 [00:04<00:27,  9.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  11%|‚ñà         | 33/308 [00:04<00:30,  9.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  11%|‚ñà         | 34/308 [00:04<00:32,  8.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  11%|‚ñà‚ñè        | 35/308 [00:04<00:33,  8.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  12%|‚ñà‚ñè        | 37/308 [00:04<00:30,  8.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  12%|‚ñà‚ñè        | 38/308 [00:04<00:30,  8.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  13%|‚ñà‚ñé        | 40/308 [00:05<00:29,  8.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  13%|‚ñà‚ñé        | 41/308 [00:05<00:30,  8.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  14%|‚ñà‚ñç        | 43/308 [00:05<00:29,  9.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  14%|‚ñà‚ñç        | 44/308 [00:05<00:31,  8.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  15%|‚ñà‚ñç        | 45/308 [00:05<00:30,  8.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  15%|‚ñà‚ñç        | 46/308 [00:05<00:34,  7.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  15%|‚ñà‚ñå        | 47/308 [00:06<00:36,  7.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  16%|‚ñà‚ñå        | 48/308 [00:06<00:35,  7.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  16%|‚ñà‚ñå        | 49/308 [00:06<00:35,  7.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  16%|‚ñà‚ñå        | 50/308 [00:06<00:40,  6.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  17%|‚ñà‚ñã        | 51/308 [00:06<00:44,  5.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  17%|‚ñà‚ñã        | 52/308 [00:06<00:39,  6.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  18%|‚ñà‚ñä        | 55/308 [00:07<00:25,  9.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  19%|‚ñà‚ñä        | 57/308 [00:07<00:27,  9.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  19%|‚ñà‚ñâ        | 58/308 [00:07<00:28,  8.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  19%|‚ñà‚ñâ        | 59/308 [00:07<00:33,  7.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  19%|‚ñà‚ñâ        | 60/308 [00:07<00:39,  6.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  20%|‚ñà‚ñâ        | 61/308 [00:08<00:38,  6.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  20%|‚ñà‚ñà        | 63/308 [00:08<00:30,  7.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  21%|‚ñà‚ñà        | 64/308 [00:08<00:32,  7.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  21%|‚ñà‚ñà        | 65/308 [00:08<00:34,  6.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  21%|‚ñà‚ñà‚ñè       | 66/308 [00:08<00:37,  6.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  22%|‚ñà‚ñà‚ñè       | 67/308 [00:08<00:38,  6.24it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  22%|‚ñà‚ñà‚ñè       | 68/308 [00:09<00:44,  5.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  22%|‚ñà‚ñà‚ñè       | 69/308 [00:09<00:38,  6.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  23%|‚ñà‚ñà‚ñé       | 70/308 [00:09<00:39,  6.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  23%|‚ñà‚ñà‚ñé       | 71/308 [00:09<00:35,  6.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  23%|‚ñà‚ñà‚ñé       | 72/308 [00:09<00:33,  7.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  24%|‚ñà‚ñà‚ñé       | 73/308 [00:09<00:37,  6.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  24%|‚ñà‚ñà‚ñç       | 75/308 [00:09<00:26,  8.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  25%|‚ñà‚ñà‚ñå       | 77/308 [00:10<00:23, 10.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  26%|‚ñà‚ñà‚ñå       | 79/308 [00:10<00:23,  9.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  26%|‚ñà‚ñà‚ñã       | 81/308 [00:10<00:26,  8.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  27%|‚ñà‚ñà‚ñã       | 82/308 [00:10<00:29,  7.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  27%|‚ñà‚ñà‚ñã       | 83/308 [00:10<00:29,  7.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  27%|‚ñà‚ñà‚ñã       | 84/308 [00:11<00:30,  7.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  28%|‚ñà‚ñà‚ñä       | 85/308 [00:11<00:28,  7.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  28%|‚ñà‚ñà‚ñä       | 86/308 [00:11<00:31,  6.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  28%|‚ñà‚ñà‚ñä       | 87/308 [00:11<00:34,  6.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  29%|‚ñà‚ñà‚ñä       | 88/308 [00:11<00:35,  6.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  29%|‚ñà‚ñà‚ñâ       | 89/308 [00:11<00:34,  6.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  29%|‚ñà‚ñà‚ñâ       | 90/308 [00:11<00:30,  7.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  30%|‚ñà‚ñà‚ñâ       | 91/308 [00:12<00:29,  7.35it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  30%|‚ñà‚ñà‚ñâ       | 92/308 [00:12<00:27,  7.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  30%|‚ñà‚ñà‚ñà       | 93/308 [00:12<00:27,  7.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  31%|‚ñà‚ñà‚ñà       | 94/308 [00:12<00:30,  7.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  31%|‚ñà‚ñà‚ñà       | 95/308 [00:12<00:31,  6.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  31%|‚ñà‚ñà‚ñà       | 96/308 [00:12<00:32,  6.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  31%|‚ñà‚ñà‚ñà‚ñè      | 97/308 [00:13<00:33,  6.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  32%|‚ñà‚ñà‚ñà‚ñè      | 99/308 [00:13<00:32,  6.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  32%|‚ñà‚ñà‚ñà‚ñè      | 100/308 [00:13<00:33,  6.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  33%|‚ñà‚ñà‚ñà‚ñé      | 101/308 [00:13<00:35,  5.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  33%|‚ñà‚ñà‚ñà‚ñé      | 102/308 [00:13<00:37,  5.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  33%|‚ñà‚ñà‚ñà‚ñé      | 103/308 [00:14<00:36,  5.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  34%|‚ñà‚ñà‚ñà‚ñç      | 104/308 [00:14<00:35,  5.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  34%|‚ñà‚ñà‚ñà‚ñç      | 105/308 [00:14<00:34,  5.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  34%|‚ñà‚ñà‚ñà‚ñç      | 106/308 [00:14<00:34,  5.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  35%|‚ñà‚ñà‚ñà‚ñç      | 107/308 [00:14<00:32,  6.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  35%|‚ñà‚ñà‚ñà‚ñå      | 109/308 [00:14<00:28,  7.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  36%|‚ñà‚ñà‚ñà‚ñå      | 110/308 [00:15<00:28,  6.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  36%|‚ñà‚ñà‚ñà‚ñå      | 111/308 [00:15<00:29,  6.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  36%|‚ñà‚ñà‚ñà‚ñã      | 112/308 [00:15<00:28,  6.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  37%|‚ñà‚ñà‚ñà‚ñã      | 113/308 [00:15<00:29,  6.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  37%|‚ñà‚ñà‚ñà‚ñã      | 114/308 [00:15<00:29,  6.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  37%|‚ñà‚ñà‚ñà‚ñã      | 115/308 [00:15<00:29,  6.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  38%|‚ñà‚ñà‚ñà‚ñä      | 117/308 [00:16<00:33,  5.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  38%|‚ñà‚ñà‚ñà‚ñä      | 118/308 [00:16<00:35,  5.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  39%|‚ñà‚ñà‚ñà‚ñä      | 119/308 [00:16<00:38,  4.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  39%|‚ñà‚ñà‚ñà‚ñâ      | 120/308 [00:16<00:36,  5.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  39%|‚ñà‚ñà‚ñà‚ñâ      | 121/308 [00:17<00:34,  5.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñâ      | 122/308 [00:17<00:32,  5.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñâ      | 123/308 [00:17<00:32,  5.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  40%|‚ñà‚ñà‚ñà‚ñà      | 124/308 [00:17<00:32,  5.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  41%|‚ñà‚ñà‚ñà‚ñà      | 125/308 [00:17<00:31,  5.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  41%|‚ñà‚ñà‚ñà‚ñà      | 127/308 [00:17<00:22,  7.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 129/308 [00:18<00:20,  8.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 130/308 [00:18<00:21,  8.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 131/308 [00:18<00:23,  7.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 132/308 [00:18<00:23,  7.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 133/308 [00:18<00:24,  7.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 134/308 [00:18<00:24,  6.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 135/308 [00:18<00:23,  7.26it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 136/308 [00:19<00:25,  6.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 137/308 [00:19<00:28,  5.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 138/308 [00:19<00:26,  6.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 139/308 [00:19<00:26,  6.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 140/308 [00:19<00:27,  6.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 141/308 [00:20<00:29,  5.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 142/308 [00:20<00:28,  5.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 143/308 [00:20<00:25,  6.41it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 144/308 [00:20<00:29,  5.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 145/308 [00:20<00:31,  5.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 146/308 [00:20<00:30,  5.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 147/308 [00:21<00:30,  5.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 148/308 [00:21<00:32,  4.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 149/308 [00:21<00:27,  5.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 150/308 [00:21<00:24,  6.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 151/308 [00:21<00:22,  6.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 152/308 [00:21<00:21,  7.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 153/308 [00:22<00:22,  6.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 154/308 [00:22<00:21,  7.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 155/308 [00:22<00:24,  6.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 156/308 [00:22<00:24,  6.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 157/308 [00:22<00:25,  5.98it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 158/308 [00:22<00:24,  6.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 159/308 [00:22<00:23,  6.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 161/308 [00:23<00:18,  7.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 162/308 [00:23<00:19,  7.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 163/308 [00:23<00:20,  6.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 165/308 [00:23<00:19,  7.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 166/308 [00:23<00:20,  7.03it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 167/308 [00:24<00:23,  6.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 169/308 [00:24<00:19,  7.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 170/308 [00:24<00:20,  6.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 171/308 [00:24<00:22,  6.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 172/308 [00:24<00:22,  6.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 173/308 [00:25<00:21,  6.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 174/308 [00:25<00:22,  6.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 175/308 [00:25<00:24,  5.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 177/308 [00:25<00:18,  7.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 178/308 [00:25<00:17,  7.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 179/308 [00:25<00:17,  7.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 180/308 [00:26<00:23,  5.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 181/308 [00:26<00:22,  5.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 182/308 [00:26<00:21,  5.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 183/308 [00:26<00:19,  6.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 184/308 [00:26<00:20,  6.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 185/308 [00:27<00:21,  5.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 186/308 [00:27<00:21,  5.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 187/308 [00:27<00:20,  6.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 188/308 [00:27<00:18,  6.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 189/308 [00:27<00:20,  5.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 190/308 [00:27<00:19,  5.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 191/308 [00:28<00:19,  6.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 192/308 [00:28<00:18,  6.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 193/308 [00:28<00:17,  6.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 194/308 [00:28<00:17,  6.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 195/308 [00:28<00:17,  6.61it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 196/308 [00:28<00:16,  6.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 197/308 [00:28<00:14,  7.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 199/308 [00:29<00:15,  6.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 200/308 [00:29<00:17,  6.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 201/308 [00:29<00:17,  6.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 202/308 [00:29<00:17,  6.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 203/308 [00:29<00:16,  6.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 204/308 [00:30<00:16,  6.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 205/308 [00:30<00:19,  5.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 206/308 [00:30<00:20,  4.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 210/308 [00:30<00:09, 10.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 212/308 [00:30<00:09, 10.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 214/308 [00:31<00:09,  9.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 216/308 [00:31<00:11,  7.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 218/308 [00:31<00:10,  9.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 220/308 [00:31<00:09,  9.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 222/308 [00:32<00:10,  8.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 223/308 [00:32<00:11,  7.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 224/308 [00:32<00:12,  6.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 225/308 [00:32<00:13,  6.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 226/308 [00:32<00:13,  6.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 227/308 [00:33<00:13,  5.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 228/308 [00:33<00:14,  5.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 229/308 [00:33<00:13,  5.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 230/308 [00:33<00:13,  5.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 231/308 [00:33<00:11,  6.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 232/308 [00:33<00:10,  7.06it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 233/308 [00:33<00:11,  6.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 234/308 [00:34<00:13,  5.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 235/308 [00:34<00:13,  5.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 236/308 [00:34<00:13,  5.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 237/308 [00:34<00:13,  5.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 238/308 [00:34<00:13,  5.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 239/308 [00:35<00:12,  5.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 240/308 [00:35<00:13,  5.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 241/308 [00:35<00:13,  5.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 242/308 [00:35<00:11,  5.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 244/308 [00:35<00:10,  6.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 245/308 [00:36<00:09,  6.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 247/308 [00:36<00:08,  7.52it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 248/308 [00:36<00:07,  7.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 249/308 [00:36<00:07,  7.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 250/308 [00:36<00:08,  7.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 252/308 [00:36<00:06,  8.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 254/308 [00:37<00:05, 10.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 256/308 [00:37<00:04, 10.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 258/308 [00:37<00:05,  8.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 259/308 [00:37<00:05,  8.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 261/308 [00:37<00:05,  8.63it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 262/308 [00:37<00:05,  8.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 263/308 [00:38<00:06,  6.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 264/308 [00:38<00:06,  6.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 265/308 [00:38<00:07,  5.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 266/308 [00:38<00:08,  5.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 267/308 [00:39<00:07,  5.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 268/308 [00:39<00:07,  5.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 269/308 [00:39<00:08,  4.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 270/308 [00:39<00:06,  5.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 271/308 [00:39<00:06,  5.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 272/308 [00:39<00:06,  6.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 273/308 [00:40<00:05,  6.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 275/308 [00:40<00:04,  7.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 276/308 [00:40<00:04,  6.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 277/308 [00:40<00:05,  5.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 278/308 [00:40<00:05,  5.67it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 279/308 [00:41<00:05,  5.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 280/308 [00:41<00:04,  5.76it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 282/308 [00:41<00:03,  7.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 284/308 [00:41<00:02,  8.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 286/308 [00:41<00:02,  8.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 287/308 [00:42<00:02,  7.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 288/308 [00:42<00:02,  7.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 289/308 [00:42<00:02,  7.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 290/308 [00:42<00:02,  6.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 291/308 [00:42<00:03,  5.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 292/308 [00:43<00:03,  4.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 293/308 [00:43<00:03,  4.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 294/308 [00:43<00:02,  4.74it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 295/308 [00:43<00:02,  5.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 296/308 [00:43<00:02,  4.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 297/308 [00:44<00:02,  4.34it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 299/308 [00:44<00:01,  5.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 302/308 [00:44<00:00,  8.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 303/308 [00:44<00:00,  7.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 304/308 [00:44<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 305/308 [00:45<00:00,  6.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 306/308 [00:45<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 307/308 [00:45<00:00,  4.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Evaluating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 308/308 [00:45<00:00,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4.339219330967246, {'wikitext_head': 4.339219330967246})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(evaluate_head_wise(model, dd[\"validation\"], collator, epochs=eval_epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be87d2d2",
   "metadata": {
    "papermill": {
     "duration": 0.017376,
     "end_time": "2024-03-23T20:55:53.104048",
     "exception": false,
     "start_time": "2024-03-23T20:55:53.086672",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Yep, the evaluation loss is similar to the training loss, indicating no overfitting. How do things look in a practical example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "276c547e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-23T20:55:53.142209Z",
     "iopub.status.busy": "2024-03-23T20:55:53.141859Z",
     "iopub.status.idle": "2024-03-23T20:55:53.170856Z",
     "shell.execute_reply": "2024-03-23T20:55:53.170377Z"
    },
    "papermill": {
     "duration": 0.050597,
     "end_time": "2024-03-23T20:55:53.171996",
     "exception": false,
     "start_time": "2024-03-23T20:55:53.121399",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wikitext_head': [' the', ' this', ' his', ' its', ' these']}\n"
     ]
    }
   ],
   "source": [
    "print(get_top_n_preds(5, model, \"The historical significance of\", tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d06f9",
   "metadata": {
    "papermill": {
     "duration": 0.017585,
     "end_time": "2024-03-23T20:55:53.207396",
     "exception": false,
     "start_time": "2024-03-23T20:55:53.189811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We see that the linear probe has learned to predict tokens that are pretty likely to follow that sentence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sh_finetuning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 536.439992,
   "end_time": "2024-03-23T20:55:55.964259",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/base/linear_probe.ipynb",
   "output_path": "notebooks/gpt2/linear_probe.ipynb",
   "parameters": {
    "eval_epochs": 1,
    "logging_steps": 100,
    "model_path": "gpt2",
    "train_epochs": 1
   },
   "start_time": "2024-03-23T20:46:59.524267",
   "version": "2.5.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "03d42341242c49fb9053f18e7eeb0b85": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_23ffaad2326e4dd380556ff8a5f2540c",
       "max": 23627,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_db1643a32d7846d380f13ba510f528ec",
       "tabbable": null,
       "tooltip": null,
       "value": 23627
      }
     },
     "23ffaad2326e4dd380556ff8a5f2540c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f7c7d3674ce49d9aced54bd7107cfb4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fadd86620504fb3bef7b4fab0a4a065": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "498fa0330b0846fd8bebe10ca1fc9a55": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2fadd86620504fb3bef7b4fab0a4a065",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_80b505178aef4bb3835f85f8b63703ca",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá23627/23627‚Äá[00:02&lt;00:00,‚Äá10248.94‚Äáexamples/s]"
      }
     },
     "58396c007b99483cbe0e1d87a45f5308": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7cbe61a9403f4939a36dd1a6a1d9a5aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "80b505178aef4bb3835f85f8b63703ca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db1643a32d7846d380f13ba510f528ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "e1870d6c6b1947cbbf6c1767d7d41ba4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f31652bba9b042d7a78f3c85d7eedfea",
        "IPY_MODEL_03d42341242c49fb9053f18e7eeb0b85",
        "IPY_MODEL_498fa0330b0846fd8bebe10ca1fc9a55"
       ],
       "layout": "IPY_MODEL_2f7c7d3674ce49d9aced54bd7107cfb4",
       "tabbable": null,
       "tooltip": null
      }
     },
     "f31652bba9b042d7a78f3c85d7eedfea": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_58396c007b99483cbe0e1d87a45f5308",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7cbe61a9403f4939a36dd1a6a1d9a5aa",
       "tabbable": null,
       "tooltip": null,
       "value": "Map:‚Äá100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
